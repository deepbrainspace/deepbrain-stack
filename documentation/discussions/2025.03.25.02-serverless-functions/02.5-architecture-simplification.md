# Architecture Simplification: Removing RocketChat Message Vectorization

## Summary

On March 25, 2025, we decided to simplify our architecture by removing the RocketChat message vectorization component. This change eliminates the need for several cloud services while maintaining the core functionality of our AI-assisted Q&A system.

## Discussion

During our review of the infrastructure diagrams, we identified that the RocketChat message vectorization workflow added significant complexity to our architecture without providing proportional value. The original design included:

1. A MongoDB Change Stream Listener to detect new messages
2. Google Pub/Sub for message event handling
3. Cloud Functions for vectorization processing
4. Additional storage in the Qdrant Vector Database

We determined that vectorizing all RocketChat messages was excessive for our primary use case, which is providing accurate answers to specific questions. The most valuable content for retrieval is the curated Q&A pairs generated by the LLM Query Worker, not general chat messages.

## Decision

We decided to:

1. Remove the RocketChat Message Vectorization workflow entirely
2. Focus only on vectorizing Q&A content from the LLM Query Worker
3. Eliminate the unnecessary GCP components (Cloud Run, some Cloud Functions, Pub/Sub)
4. Simplify our system architecture diagrams to reflect these changes

## Benefits

This architectural change provides several benefits:

1. **Reduced complexity**: Fewer components to maintain and troubleshoot
2. **Lower costs**: Elimination of several cloud services reduces operational expenses
3. **Focused data quality**: Vector database contains only high-value Q&A content
4. **Simplified operations**: Less infrastructure to monitor and manage
5. **Clearer architecture**: Easier to understand and explain to new team members

## Implementation

The implementation of this change involves:

1. Removing the MongoDB Change Stream Listener service
2. Decommissioning the related Google Pub/Sub topics and subscriptions
3. Removing the associated Cloud Functions
4. Updating our infrastructure diagrams to reflect the simplified architecture
5. Updating our documentation to reflect the new approach

## Conclusion

By focusing our vectorization efforts solely on Q&A content, we've created a more streamlined, cost-effective architecture while maintaining the core functionality needed for our AI-assisted support system. This change aligns with our principle of keeping the architecture as simple as possible while meeting all functional requirements.